{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "vanilla-usage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69010"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getpid()#看看有没有在用gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "upper-capture",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "framed-joyce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user1/.conda/envs/ENIO/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/user1/.conda/envs/ENIO/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/user1/.conda/envs/ENIO/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/user1/.conda/envs/ENIO/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/user1/.conda/envs/ENIO/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/user1/.conda/envs/ENIO/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import scipy \n",
    "import joblib\n",
    "from netCDF4 import Dataset\n",
    "import netCDF4 as nc \n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, Callback\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.layers import Input \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ahead-surname",
   "metadata": {},
   "outputs": [],
   "source": [
    "soda_label = pd.read_csv('./ENSO/data/df_SODA_label.csv')['label']\n",
    "sst_SODA = pd.read_csv('./ENSO/data/df_sst_SODA.csv')\n",
    "t300_SODA = pd.read_csv('./ENSO/data/df_t300_SODA.csv')\n",
    "ua_SODA = pd.read_csv('./ENSO/data/df_ua_SODA.csv')\n",
    "va_SODA = pd.read_csv('./ENSO/data/df_va_SODA.csv')\n",
    "sst_SODA.pop('year_month')\n",
    "t300_SODA.pop('year_month')\n",
    "va_SODA.pop('year_month')\n",
    "ua_SODA.pop('year_month')\n",
    "sst_SODA = np.array(sst_SODA).reshape(100,36,24,72,1)[:,:12,:,:,:]\n",
    "t300_SODA = np.array(t300_SODA).reshape(100,36,24,72,1)[:,:12,:,:,:]\n",
    "va_SODA = np.array(va_SODA).reshape(100,36,24,72,1)[:,:12,:,:,:]\n",
    "ua_SODA = np.array(ua_SODA).reshape(100,36,24,72,1)[:,:12,:,:,:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "muslim-drilling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 12, 24, 72, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 训练特征，保证和训练集一致\n",
    "tr_features = np.concatenate([sst_SODA,t300_SODA,va_SODA,ua_SODA],axis=-1)\n",
    "tr_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "closed-shakespeare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 24)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 训练标签，取后24个\n",
    "tr_labels = np.array(soda_label).reshape(-1,36)[:,12:]\n",
    "tr_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "successful-spice",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### 训练集验证集划分\n",
    "tr_len     = int(tr_features.shape[0] * 0.8)\n",
    "tr_fea     = tr_features[:tr_len,:].copy()\n",
    "tr_label   = tr_labels[:tr_len,:].copy()\n",
    " \n",
    "val_fea     = tr_features[tr_len:,:].copy()\n",
    "val_label   = tr_labels[tr_len:,:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "heated-gilbert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 12, 24, 72, 4)     0         \n",
      "_________________________________________________________________\n",
      "conv3d (Conv3D)              (None, 9, 9, 32, 64)      671808    \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 4, 4, 16, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 1, 1, 1, 128)      2097280   \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 24)                792       \n",
      "=================================================================\n",
      "Total params: 2,780,216\n",
      "Trainable params: 2,780,216\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def RMSE(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))\n",
    "\n",
    "def RMSE_fn(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.power(np.array(y_true, float).reshape(-1, 1) - np.array(y_pred, float).reshape(-1, 1), 2)))\n",
    "\n",
    "def build_model():\n",
    "    input_shape = (12,24,72,4)\n",
    "    inp    = Input(shape=input_shape) \n",
    "    x    = Conv3D(64,(4,16,41), activation='relu', input_shape=input_shape)(inp)\n",
    "    x = MaxPooling3D((2,2,2))(x)\n",
    "    x    = Conv3D(128,(4,4,16), activation='relu')(x)\n",
    "    # x = MaxPooling3D((4,4,1))(x)\n",
    "    # x    = Conv3D(128,2, activation='relu')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(64, activation='relu')(x)  \n",
    "    x = Dropout(0.25)(x) \n",
    "    x = Dense(32, activation='relu')(x)   \n",
    "    x = Dropout(0.25)(x)  \n",
    "    output = Dense(24, activation='linear')(x)   \n",
    "\n",
    "    model  = Model(inputs=inp, outputs=output)\n",
    "    adam = tf.keras.optimizers.Adam(lr=1e-3,beta_1=0.99,beta_2 = 0.99) \n",
    "    model.compile(optimizer=adam, loss=RMSE)\n",
    "    return model\n",
    "#### 构建模型\n",
    "model_cnn     = build_model()\n",
    "#### 模型存储的位置\n",
    "model_weights = './model/model_mlp_baseline.h5'\n",
    "#保存最佳模型\n",
    "checkpoint = ModelCheckpoint(model_weights, monitor='val_loss', verbose=0, save_best_only=True, mode='min',\n",
    "                             save_weights_only=True)\n",
    "#Reduce learning rate when a metric has stopped improving.\n",
    "plateau        = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1, min_delta=1e-4, mode='min')\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=20)\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-reconstruction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/2000\n",
      "80/80 [==============================] - 219s 3s/step - loss: 0.8309 - val_loss: 1.2677\n",
      "Epoch 2/2000\n",
      "80/80 [==============================] - 216s 3s/step - loss: 1.6511 - val_loss: 1.7875\n",
      "Epoch 3/2000\n",
      "80/80 [==============================] - 216s 3s/step - loss: 1.6613 - val_loss: 1.3791\n",
      "Epoch 4/2000\n",
      "80/80 [==============================] - 217s 3s/step - loss: 1.1585 - val_loss: 1.0380\n",
      "Epoch 5/2000\n",
      "80/80 [==============================] - 215s 3s/step - loss: 0.9852 - val_loss: 1.1403\n",
      "Epoch 6/2000\n",
      "80/80 [==============================] - 214s 3s/step - loss: 0.9827 - val_loss: 1.3063\n",
      "Epoch 7/2000\n",
      "80/80 [==============================] - 210s 3s/step - loss: 1.0553 - val_loss: 1.2360\n",
      "Epoch 8/2000\n",
      "80/80 [==============================] - 214s 3s/step - loss: 1.0209 - val_loss: 1.1691\n",
      "Epoch 9/2000\n",
      "80/80 [==============================] - 217s 3s/step - loss: 0.9535 - val_loss: 0.9645\n",
      "Epoch 10/2000\n"
     ]
    }
   ],
   "source": [
    "history        = model_cnn.fit(tr_fea,tr_label,\n",
    "                    validation_data=(val_fea, val_label),\n",
    "                    batch_size=4096, epochs=2000,\n",
    "                    callbacks=[plateau, checkpoint, early_stopping],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-position",
   "metadata": {},
   "outputs": [],
   "source": [
    "del val_label\n",
    "del val_fea\n",
    "del tr_fea\n",
    "del tr_label\n",
    "del sst_SODA\n",
    "del t300_SODA\n",
    "del ua_SODA\n",
    "del va_SODA\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-harassment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-teach",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sst_CMIP = pd.read_csv('./ENSO/data/df_sst_CMIP.csv')\n",
    "t300_CMIP = pd.read_csv('./ENSO/data/df_t300_CMIP.csv')\n",
    "ua_CMIP = pd.read_csv('./ENSO/data/df_ua_CMIP.csv')\n",
    "va_CMIP = pd.read_csv('./ENSO/data/df_va_CMIP.csv')\n",
    "\n",
    "\n",
    "cmip_label = pd.read_csv('./ENSO/data/df_CMIP_label.csv')['label']\n",
    "\n",
    "\n",
    "sst_CMIP.pop('year_month')\n",
    "t300_CMIP.pop('year_month')\n",
    "va_CMIP.pop('year_month')\n",
    "ua_CMIP.pop('year_month')\n",
    "sst_CMIP = np.array(sst_CMIP).reshape(-1,36,24,72,1)[:,:12,:,:,:]\n",
    "t300_CMIP = np.array(t300_CMIP).reshape(-1,36,24,72,1)[:,:12,:,:,:]\n",
    "va_CMIP = np.array(va_CMIP).reshape(-1,36,24,72,1)[:,:12,:,:,:]\n",
    "ua_CMIP = np.array(ua_CMIP).reshape(-1,36,24,72,1)[:,:12,:,:,:]\n",
    "tr_features2 = np.concatenate([sst_CMIP,t300_CMIP,va_CMIP,ua_CMIP],axis=-1)\n",
    "tr_features.shape\n",
    "tr_labels2 = np.array(cmip_label).reshape(-1,36)[:,12:]\n",
    "tr_labels.shape\n",
    "\n",
    "### 训练集验证集划分\n",
    "tr_len2     = int(tr_features.shape[0] * 0.8)\n",
    "tr_fea2     = tr_features[:tr_len,:].copy()\n",
    "tr_label2   = tr_labels[:tr_len,:].copy()\n",
    " \n",
    "val_fea2     = tr_features[tr_len:,:].copy()\n",
    "val_label2   = tr_labels[tr_len:,:].copy()\n",
    "\n",
    "\n",
    "history        = model_cnn.fit(tr_fea2,tr_label2,\n",
    "                    validation_data=(val_fea2, val_label2),\n",
    "                    batch_size=4096, epochs=2000,\n",
    "                    callbacks=[plateau, checkpoint, early_stopping],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-original",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-student",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = build_model()\n",
    "model_cnn.load_weights('./model/model_mlp_baseline.h5')\n",
    "\n",
    "prediction = model_cnn.predict(val_fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-detroit",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.power(np.array(y_true, float).reshape(-1, 1) - np.array(y_pred, float).reshape(-1, 1), 2)))\n",
    "\n",
    "def score(y_true, y_preds):\n",
    "    accskill_score = 0\n",
    "    rmse_scores    = 0\n",
    "    a = [1.5] * 4 + [2] * 7 + [3] * 7 + [4] * 6\n",
    "    y_true_mean = np.mean(y_true,axis=0) \n",
    "    y_pred_mean = np.mean(y_preds,axis=0) \n",
    "#     print(y_true_mean.shape, y_pred_mean.shape)\n",
    "\n",
    "    for i in range(24): \n",
    "        fenzi = np.sum((y_true[:,i] -  y_true_mean[i]) *(y_preds[:,i] -  y_pred_mean[i]) ) \n",
    "        fenmu = np.sqrt(np.sum((y_true[:,i] -  y_true_mean[i])**2) * np.sum((y_preds[:,i] -  y_pred_mean[i])**2) ) \n",
    "        cor_i = fenzi / fenmu\n",
    "    \n",
    "        accskill_score += a[i] * np.log(i+1) * cor_i\n",
    "        rmse_score   = rmse(y_true[:,i], y_preds[:,i])\n",
    "#         print(cor_i,  2 / 3.0 * a[i] * np.log(i+1) * cor_i - rmse_score)\n",
    "        rmse_scores += rmse_score \n",
    "    \n",
    "    return 2 / 3.0 * accskill_score - rmse_scores\n",
    "\n",
    "\n",
    "print('score', score(y_true = val_label, y_preds = prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-ENIO] *",
   "language": "python",
   "name": "conda-env-.conda-ENIO-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
